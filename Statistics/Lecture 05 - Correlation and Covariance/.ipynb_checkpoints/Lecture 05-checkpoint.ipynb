{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner Python and Math for Data Science\n",
    "## Lecture 5 - Correlation and Covariance\n",
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Purpose:__ The purpose of this lecture is to understand correlation and covariance.\n",
    "\n",
    "__At the end of this lecture you will be able to:__\n",
    "> 1. Understand some summary statistics such as Correlation and Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Correlation and Covariance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Overview:__ \n",
    "- We can use a series of statistics to evaluate the relationship between the two variables:\n",
    "> 1. __[Covariance](https://en.wikipedia.org/wiki/Covariance):__ Covariance measures how the two variables vary with each other. Covariance investigates if the two variables tend to increase and decrease together or if one variable increases when the other decreases or vice versa or if the variables do not vary at all with each other (covariance of 0)\n",
    ">> - The formula for Covariance can be represented in terms of Expected Value and Variance: \n",
    "<center> $Cov(X, Y) = \\sigma_{XY} = E[XY] - E[X][Y] = E[(X - \\mu_{X})(Y - \\mu_{Y})]$ </center> \n",
    "\n",
    ">> - The formula for Covariance can also be represented in the following way:\n",
    "<center> $Cov(X, Y) = \\sigma_{XY} = \\frac{\\sum_{i=1}^{n} (x_{i} - \\mu_{x})(y_{i} - \\mu_{y})}{n}$ </center>\n",
    "\n",
    ">> - If two variables $X$ and $Y$ are independent, then $Cov(X,Y) = 0$, but the opposite is not always true \n",
    ">> - The problem with Covariance is that it is not normalized and therefore difficult to determine if the magnitude of Covariance is considered strong or weak. This warrants a normalized measure of variable association of which we define Correlation below \n",
    "> 2. __[Correlation](https://en.wikipedia.org/wiki/Correlation_and_dependence):__ Correlation is very similar to Covariance but is scaled by the Standard Deviations of the two variables such that Correlation can only range between -1 and +1. \n",
    ">> - The formula for Correlation can be represented in the following way:\n",
    "<center> $Cor(X, Y) = r_{XY} = \\frac{\\frac{\\sum_{i=1}^{n} (x_{i} - \\mu_{x})(y_{i} - \\mu_{y})}{n}}{\\sigma_x \\sigma_y}$ </center> \n",
    "\n",
    ">> - We can now interpret the mangitude of the Correlation and conclude that if the Correlation is positive, the variables move in the same direction, if the Correlation is negative is negative, the two variables move in opposite direction, and if the Correlation is 0, the variables do move together in either direction \n",
    "\n",
    "__Helpful Points:__\n",
    "1. It is possible to create Covariance and Correlation Matrices which calculates the Covariance and Correlation, respectively, of a series of variables and summarizes this information into a symmetric matrix\n",
    "2. Typically, we calculate the Covariance and Correlation Matrices of a data set to observe all the paired covariance and correlation values for every pair of variables \n",
    "\n",
    "__Practice:__ Examples of Correlation and Covariance in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import math \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data to analyze \n",
    "nba_df = pd.read_csv(\"NBA_GameLog_2010_2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 (Covariance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of nba data for cov and cor calculations \n",
    "nba_df_subset = nba_df.loc[:, ['Tm.Pts', 'Tm.FG_Perc', 'Tm.3P_Perc', 'Tm.FT_Perc', \n",
    "                               'Tm.TRB','Tm.AST', 'Tm.STL', 'Tm.BLK', 'Tm.TOV', 'Tm.PF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tm.Pts</th>\n",
       "      <th>Tm.FG_Perc</th>\n",
       "      <th>Tm.3P_Perc</th>\n",
       "      <th>Tm.FT_Perc</th>\n",
       "      <th>Tm.TRB</th>\n",
       "      <th>Tm.AST</th>\n",
       "      <th>Tm.STL</th>\n",
       "      <th>Tm.BLK</th>\n",
       "      <th>Tm.TOV</th>\n",
       "      <th>Tm.PF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tm.Pts</th>\n",
       "      <td>147.523854</td>\n",
       "      <td>0.468805</td>\n",
       "      <td>0.593105</td>\n",
       "      <td>0.216965</td>\n",
       "      <td>10.056589</td>\n",
       "      <td>34.856841</td>\n",
       "      <td>4.510063</td>\n",
       "      <td>1.680997</td>\n",
       "      <td>-4.704925</td>\n",
       "      <td>7.426513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm.FG_Perc</th>\n",
       "      <td>0.468805</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.072631</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>-0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm.3P_Perc</th>\n",
       "      <td>0.593105</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>-0.072651</td>\n",
       "      <td>0.198534</td>\n",
       "      <td>-0.003194</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.002567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm.FT_Perc</th>\n",
       "      <td>0.216965</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.010602</td>\n",
       "      <td>-0.037013</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>-0.003037</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>-0.009051</td>\n",
       "      <td>0.003774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm.TRB</th>\n",
       "      <td>10.056589</td>\n",
       "      <td>-0.072631</td>\n",
       "      <td>-0.072651</td>\n",
       "      <td>-0.037013</td>\n",
       "      <td>42.333663</td>\n",
       "      <td>1.098065</td>\n",
       "      <td>-1.750161</td>\n",
       "      <td>2.815002</td>\n",
       "      <td>3.186443</td>\n",
       "      <td>-0.327592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm.AST</th>\n",
       "      <td>34.856841</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>0.198534</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>1.098065</td>\n",
       "      <td>25.413989</td>\n",
       "      <td>1.687982</td>\n",
       "      <td>0.881108</td>\n",
       "      <td>-0.886902</td>\n",
       "      <td>-0.567222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm.STL</th>\n",
       "      <td>4.510063</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>-0.003194</td>\n",
       "      <td>-0.003037</td>\n",
       "      <td>-1.750161</td>\n",
       "      <td>1.687982</td>\n",
       "      <td>8.386989</td>\n",
       "      <td>0.032831</td>\n",
       "      <td>1.308719</td>\n",
       "      <td>0.273774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm.BLK</th>\n",
       "      <td>1.680997</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>2.815002</td>\n",
       "      <td>0.881108</td>\n",
       "      <td>0.032831</td>\n",
       "      <td>6.647865</td>\n",
       "      <td>0.451256</td>\n",
       "      <td>0.036096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm.TOV</th>\n",
       "      <td>-4.704925</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>-0.009051</td>\n",
       "      <td>3.186443</td>\n",
       "      <td>-0.886902</td>\n",
       "      <td>1.308719</td>\n",
       "      <td>0.451256</td>\n",
       "      <td>14.616469</td>\n",
       "      <td>2.450163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm.PF</th>\n",
       "      <td>7.426513</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>-0.327592</td>\n",
       "      <td>-0.567222</td>\n",
       "      <td>0.273774</td>\n",
       "      <td>0.036096</td>\n",
       "      <td>2.450163</td>\n",
       "      <td>18.883561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tm.Pts  Tm.FG_Perc  Tm.3P_Perc  Tm.FT_Perc     Tm.TRB  \\\n",
       "Tm.Pts      147.523854    0.468805    0.593105    0.216965  10.056589   \n",
       "Tm.FG_Perc    0.468805    0.003133    0.002757    0.000073  -0.072631   \n",
       "Tm.3P_Perc    0.593105    0.002757    0.012074    0.000221  -0.072651   \n",
       "Tm.FT_Perc    0.216965    0.000073    0.000221    0.010602  -0.037013   \n",
       "Tm.TRB       10.056589   -0.072631   -0.072651   -0.037013  42.333663   \n",
       "Tm.AST       34.856841    0.153645    0.198534   -0.001035   1.098065   \n",
       "Tm.STL        4.510063    0.004388   -0.003194   -0.003037  -1.750161   \n",
       "Tm.BLK        1.680997    0.005725    0.003556   -0.000288   2.815002   \n",
       "Tm.TOV       -4.704925    0.007339    0.005498   -0.009051   3.186443   \n",
       "Tm.PF         7.426513   -0.000621    0.002567    0.003774  -0.327592   \n",
       "\n",
       "               Tm.AST    Tm.STL    Tm.BLK     Tm.TOV      Tm.PF  \n",
       "Tm.Pts      34.856841  4.510063  1.680997  -4.704925   7.426513  \n",
       "Tm.FG_Perc   0.153645  0.004388  0.005725   0.007339  -0.000621  \n",
       "Tm.3P_Perc   0.198534 -0.003194  0.003556   0.005498   0.002567  \n",
       "Tm.FT_Perc  -0.001035 -0.003037 -0.000288  -0.009051   0.003774  \n",
       "Tm.TRB       1.098065 -1.750161  2.815002   3.186443  -0.327592  \n",
       "Tm.AST      25.413989  1.687982  0.881108  -0.886902  -0.567222  \n",
       "Tm.STL       1.687982  8.386989  0.032831   1.308719   0.273774  \n",
       "Tm.BLK       0.881108  0.032831  6.647865   0.451256   0.036096  \n",
       "Tm.TOV      -0.886902  1.308719  0.451256  14.616469   2.450163  \n",
       "Tm.PF       -0.567222  0.273774  0.036096   2.450163  18.883561  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_df_subset_cov = pd.DataFrame(np.cov(nba_df_subset.T)) # cov function calculates row based covariances by default, but we want column covariances\n",
    "nba_df_subset_cov.columns = ['Tm.Pts', 'Tm.FG_Perc', 'Tm.3P_Perc', 'Tm.FT_Perc', \n",
    "                               'Tm.TRB','Tm.AST', 'Tm.STL', 'Tm.BLK', 'Tm.TOV', 'Tm.PF']\n",
    "nba_df_subset_cov.index = ['Tm.Pts', 'Tm.FG_Perc', 'Tm.3P_Perc', 'Tm.FT_Perc', \n",
    "                               'Tm.TRB','Tm.AST', 'Tm.STL', 'Tm.BLK', 'Tm.TOV', 'Tm.PF']\n",
    "nba_df_subset_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.cov of        Tm.Pts  Tm.FG_Perc  Tm.3P_Perc  Tm.FT_Perc  Tm.TRB  Tm.AST  Tm.STL  \\\n",
       "0         120       0.529       0.583       0.724      35      30      16   \n",
       "1         100       0.410       0.250       0.912      47      18       5   \n",
       "2         110       0.449       0.304       0.885      40      21       8   \n",
       "3          97       0.463       0.333       0.818      46      21       4   \n",
       "4         113       0.541       0.375       0.789      47      17       2   \n",
       "5          83       0.398       0.125       0.652      35      10       7   \n",
       "6         125       0.517       0.421       0.900      44      30       4   \n",
       "7         114       0.543       0.462       0.833      42      23       7   \n",
       "8          97       0.452       0.267       0.739      47      19       7   \n",
       "9         121       0.545       0.350       0.621      48      27      10   \n",
       "10         99       0.429       0.278       0.800      47      20       7   \n",
       "11        105       0.427       0.400       0.750      43      23       7   \n",
       "12        105       0.500       0.400       0.731      39      21       6   \n",
       "13         88       0.372       0.182       0.824      52      15       5   \n",
       "14         76       0.388       0.368       0.429      41      18       8   \n",
       "15        100       0.514       0.500       0.750      42      17       7   \n",
       "16         88       0.500       0.333       0.875      27      16       7   \n",
       "17        146       0.591       0.524       0.795      51      37       5   \n",
       "18        107       0.456       0.174       0.724      42      21       6   \n",
       "19         80       0.360       0.154       0.636      50      16       9   \n",
       "20        118       0.500       0.375       0.750      43      32      12   \n",
       "21        111       0.518       0.500       0.842      37      25      10   \n",
       "22        130       0.533       0.647       0.724      51      32      12   \n",
       "23        110       0.484       0.375       0.778      43      26      13   \n",
       "24         96       0.446       0.300       0.640      39      26      13   \n",
       "25         98       0.414       0.421       0.900      41      15       6   \n",
       "26        112       0.489       0.450       0.680      39      22      12   \n",
       "27        104       0.481       0.348       0.833      40      21       2   \n",
       "28        110       0.506       0.333       0.774      37      19      12   \n",
       "29         84       0.443       0.400       0.615      30      19      10   \n",
       "...       ...         ...         ...         ...     ...     ...     ...   \n",
       "20480     104       0.429       0.269       0.806      38      15      10   \n",
       "20481     107       0.488       0.400       0.714      42      30       4   \n",
       "20482     112       0.455       0.385       0.833      40      34       5   \n",
       "20483      93       0.367       0.333       0.774      44      21       6   \n",
       "20484     102       0.430       0.229       0.769      39      24       6   \n",
       "20485     104       0.400       0.324       0.739      54      23       9   \n",
       "20486     129       0.505       0.385       0.955      46      29       9   \n",
       "20487     127       0.598       0.444       0.808      40      24      10   \n",
       "20488     119       0.511       0.261       0.680      41      24      12   \n",
       "20489     124       0.495       0.382       0.655      43      22       7   \n",
       "20490      88       0.402       0.294       0.813      45      12       8   \n",
       "20491     115       0.467       0.370       0.760      38      28       9   \n",
       "20492     118       0.506       0.500       0.833      36      31      10   \n",
       "20493     106       0.486       0.412       0.714      39      17       5   \n",
       "20494     103       0.481       0.364       0.773      44      21       7   \n",
       "20495     105       0.506       0.368       0.875      48      27       8   \n",
       "20496     102       0.483       0.269       0.786      34      18       9   \n",
       "20497     114       0.450       0.286       0.941      42      28       8   \n",
       "20498     109       0.453       0.318       0.727      43      22      10   \n",
       "20499      98       0.416       0.241       0.850      42      16       6   \n",
       "20500     101       0.424       0.344       0.783      46      19       7   \n",
       "20501     103       0.451       0.292       0.815      42      21       8   \n",
       "20502     115       0.538       0.417       0.840      33      21      16   \n",
       "20503     111       0.506       0.435       0.591      38      27       6   \n",
       "20504     119       0.465       0.294       0.773      44      28       7   \n",
       "20505     116       0.467       0.320       0.880      50      26       7   \n",
       "20506     121       0.524       0.429       0.889      45      29      13   \n",
       "20507     101       0.385       0.241       0.828      45      21       5   \n",
       "20508      92       0.430       0.208       0.619      46      20       4   \n",
       "20509     105       0.450       0.345       0.793      43      18       6   \n",
       "\n",
       "       Tm.BLK  Tm.TOV  Tm.PF  \n",
       "0           6      10     25  \n",
       "1           7      12     24  \n",
       "2           3      19     21  \n",
       "3           7      11     15  \n",
       "4          10      16     20  \n",
       "5          11       7     20  \n",
       "6           9       8     33  \n",
       "7           3      15     19  \n",
       "8           6      13     20  \n",
       "9           3      14     19  \n",
       "10          5      14     17  \n",
       "11          6       8     19  \n",
       "12         11      15     22  \n",
       "13          7       6     17  \n",
       "14          3      13     20  \n",
       "15          5      14     17  \n",
       "16          9      13     19  \n",
       "17          6       9     26  \n",
       "18          2       6     16  \n",
       "19          3       8     22  \n",
       "20          6       8     24  \n",
       "21          4      12     19  \n",
       "22          3      12     17  \n",
       "23          7      14     20  \n",
       "24          4      11     20  \n",
       "25          7      13     25  \n",
       "26          4      10     29  \n",
       "27          4      14     20  \n",
       "28         11      10     14  \n",
       "29          5      16     16  \n",
       "...       ...     ...    ...  \n",
       "20480       2      15     25  \n",
       "20481       1      12     23  \n",
       "20482       6      10     17  \n",
       "20483       7      12     21  \n",
       "20484       4      18     28  \n",
       "20485       6      19     26  \n",
       "20486       5      10     19  \n",
       "20487       4      11     23  \n",
       "20488       3      12     20  \n",
       "20489       0      10     31  \n",
       "20490       1      14     23  \n",
       "20491       3      14     20  \n",
       "20492       3      12     18  \n",
       "20493       8      13     22  \n",
       "20494       6      19     24  \n",
       "20495       5      17     13  \n",
       "20496       0      10     13  \n",
       "20497       9      12     25  \n",
       "20498      10      11     29  \n",
       "20499       4      15     28  \n",
       "20500       5      14     25  \n",
       "20501      10       6     20  \n",
       "20502       7      16     22  \n",
       "20503       7      12     14  \n",
       "20504      10      17     29  \n",
       "20505       5       9     26  \n",
       "20506       3      19     22  \n",
       "20507       5      12     18  \n",
       "20508       7      12     24  \n",
       "20509       4      15     17  \n",
       "\n",
       "[20510 rows x 10 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_metrix= nba_df_subset.cov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the covariance between every pair of variables in the subsetted data set. For example:\n",
    "- The covariance between Team Points and Team Total Rebounds is 10.05\n",
    "- The covariance between Team 3 Point Shot Percentage and Team Steal sis -0.003\n",
    "\n",
    "Note:\n",
    "1. The matrix is symmetric so you only need to consider either the upper right triangle or the lower left triangle \n",
    "2. The diagonal elements represent the covariance of the variable onto itself which is just the variance of that variable (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# variance of each column which is the diagonal elements of the covariance matrix \n",
    "nba_df_subset.var(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 (Correlation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nba_df_subset_corr = pd.DataFrame(np.corrcoef(nba_df_subset.T)) # corrcoef function calculates row based correlations by default, but we want column correlations\n",
    "nba_df_subset_corr.columns = ['Tm.Pts', 'Tm.FG_Perc', 'Tm.3P_Perc', 'Tm.FT_Perc', \n",
    "                               'Tm.TRB','Tm.AST', 'Tm.STL', 'Tm.BLK', 'Tm.TOV', 'Tm.PF']\n",
    "nba_df_subset_corr.index = ['Tm.Pts', 'Tm.FG_Perc', 'Tm.3P_Perc', 'Tm.FT_Perc', \n",
    "                               'Tm.TRB','Tm.AST', 'Tm.STL', 'Tm.BLK', 'Tm.TOV', 'Tm.PF']\n",
    "nba_df_subset_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the correlation between every pair of variables in the subsetted data set. For example:\n",
    "- The correlation between Team Points and Team Total Rebounds is 0.127\n",
    "- The correlation between Team 3 Point Shot Percentage and Team Steal is -0.01\n",
    "\n",
    "Note:\n",
    "1. The matrix is symmetric so you only need to consider either the upper right triangle or the lower left triangle \n",
    "2. The diagonal elements represent the correlation of the variable onto itself which is perfect correlation (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are going to analyze graphically the relationship between __Tm.Pts__ and __Tm.FG_Perc__ which are highly correlated, as well as __Tm.3P_Perc__ and __Tm.TOV__ which have a low correlation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will normalize the features (calculate their z-score) by subtracting their mean and dividing by their standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pts_Norm = (nba_df_subset['Tm.Pts']-np.mean(nba_df_subset['Tm.Pts']))/np.std(nba_df_subset['Tm.Pts'])\n",
    "FG_Perc_Norm = (nba_df_subset['Tm.FG_Perc']-np.mean(nba_df_subset['Tm.FG_Perc']))/np.std(nba_df_subset['Tm.FG_Perc'])\n",
    "\n",
    "ThreeP_Perc_Norm = (nba_df_subset['Tm.3P_Perc']-np.mean(nba_df_subset['Tm.3P_Perc']))/np.std(nba_df_subset['Tm.3P_Perc'])\n",
    "TOV_Norm = (nba_df_subset['Tm.TOV']-np.mean(nba_df_subset['Tm.TOV']))/np.std(nba_df_subset['Tm.TOV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(nba_df_subset['Tm.Pts'])\n",
    "plt.plot(nba_df_subset['Tm.FG_Perc'])\n",
    "plt.legend(['Pts','FG_Perc'])\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(Pts_Norm,alpha = 0.5)\n",
    "plt.plot(FG_Perc_Norm,alpha = 0.5)\n",
    "plt.legend(['Normalized Pts','Normalized FG_Perc'])\n",
    "plt.subplot(3,1,3)\n",
    "plt.scatter(Pts_Norm,FG_Perc_Norm,alpha = 0.1)\n",
    "plt.xlabel('Normalized Pts')\n",
    "plt.ylabel('Normalized FG_Perc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is a relationship between 'Pts' and 'FG_Perc'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(nba_df_subset['Tm.3P_Perc'])\n",
    "plt.plot(nba_df_subset['Tm.TOV'])\n",
    "plt.legend(['3P_Perc','TOV'])\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(ThreeP_Perc_Norm,alpha = 0.5)\n",
    "plt.plot(TOV_Norm,alpha = 0.5)\n",
    "plt.legend(['Normalized ThreeP_Perc','Normalized TOV'])\n",
    "plt.subplot(3,1,3)\n",
    "plt.scatter(ThreeP_Perc_Norm,TOV_Norm,alpha = 0.1)\n",
    "plt.xlabel('Normalized ThreeP_Perc')\n",
    "plt.ylabel('Normalized TOV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there is a relationship between '3P_Perc' and 'TOV'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Select the quantitative variables from the Seattle Home Price data and develop both a Covariance and Correlation Matrix as shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df = pd.read_csv(\"SeattleHomePrices.csv\")\n",
    "# Write your code here \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 (Correlation Heat Map):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.corrcoef(nba_df_subset.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Select the quantitative variables from the Seattle Home Price data and develop both a Covariance and Correlation Matrix as shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df = pd.read_csv(\"SeattleHomePrices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df_subset = home_df.loc[:, ['PRICE', 'BEDS', 'BATHS', 'SQUARE FEET', 'LOT SIZE',\n",
    "                               'YEAR BUILT', 'DAYS ON MARKET', '$/SQUARE FEET', 'HOA/MONTH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df_subset = home_df_subset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df_subset_cov = pd.DataFrame(np.cov(home_df_subset.T))\n",
    "home_df_subset_cov.columns = ['PRICE', 'BEDS', 'BATHS', 'SQUARE FEET', 'LOT SIZE',\n",
    "                               'YEAR BUILT', 'DAYS ON MARKET', '$/SQUARE FEET', 'HOA/MONTH']\n",
    "home_df_subset_cov.index = ['PRICE', 'BEDS', 'BATHS', 'SQUARE FEET', 'LOT SIZE',\n",
    "                               'YEAR BUILT', 'DAYS ON MARKET', '$/SQUARE FEET', 'HOA/MONTH']\n",
    "home_df_subset_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df_subset_corr = pd.DataFrame(np.corrcoef(home_df_subset.T))\n",
    "home_df_subset_corr.columns = ['PRICE', 'BEDS', 'BATHS', 'SQUARE FEET', 'LOT SIZE',\n",
    "                               'YEAR BUILT', 'DAYS ON MARKET', '$/SQUARE FEET', 'HOA/MONTH']\n",
    "home_df_subset_corr.index = ['PRICE', 'BEDS', 'BATHS', 'SQUARE FEET', 'LOT SIZE',\n",
    "                               'YEAR BUILT', 'DAYS ON MARKET', '$/SQUARE FEET', 'HOA/MONTH']\n",
    "home_df_subset_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
